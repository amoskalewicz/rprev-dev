---
title: "Prevalence Test"
author: "Stuart Lacy"
date: "8 April 2016"
output: 
  html_document: 
    number_sections: yes
    theme: lumen
    toc: yes
    toc_float:
        collapsed: false
    code_folding: hide
---

# Introduction

This script provides a test function for my tinkerings in the `prevR` package. I've currently just limited my tinkerings to `incidence` and `prevalence` functions.

# Setup

```{r, echo=F, message=F, warning=F}
library(knitr)
opts_chunk$set(echo=T, message=F, warning=F)
```

```{r, echo=T}
library(Rcpp)
library(devtools)
devtools::load_all()
library(abind)
library(dplyr)
library(rms)
library(survival)

registry_data <- readRDS("../data/registry_data.rds")
N_years <- 10
cure <- 3
```

# Incidence test

```{r, echo=T}
incidence_test <- function () {
  registry_years <- c("2004-09-01", "2005-09-01", "2006-09-01", "2007-09-01", "2008-09-01",
                      "2009-09-01", "2010-09-01", "2011-09-01", "2012-09-01", "2013-09-01")
  registry_start_year <- 2
  registry_end_year <- 9
  correct_inc <- incidence_current(load_data(registry_data), registry_years, registry_start_year, 
                                   registry_end_year)
  correct_inc
}
incidence_test()
```

And for my development version...
```{r, echo=T}
dev_inc <- incidence_dev(registry_data$DateOfDiag, sapply(5:13, function(x) sprintf("20%02d-09-01", x)))
dev_inc
```

Perfect! The changes I've made are:

  + Don't need to pass in the whole vector of `registry_years` which aren't used, instead just pass in the ones of interest to this function, thereby removing the need to pass in starting / finishing indices
  + Likewise can then calculate the required number of years to investigated as the length of the passed in vector
  + Don't need to pass in the whole data frame, only the dates of diagnosis are required to calculate incidence, therefore the `load_data` function isn't needed here either
  + Changed the calculation for number of incident events from determining the subset of events in the desired time frame, subsetting the vector with these indices, and then calculating its length, to just calculating the sum of subset of events as it's quicker
  + Changed the for loop into an sapply implementation for readability and encapsulation
  + Removed the storing of the total incident cases in a variable as it's only used once
  
# Testing Environment

Firstly I need to setup a desired outcome so I can check if my code is working correctly. As before I've renamed the current `prevalence` function to `prevalent_current` and my development version is found at `prevalence_dev`.

A second data set is required for this calculation, saved as *data/population_data_mx.rds*, **NB: I've changed this from a .rda to .rds file for readability and reproducibility, and also changed it from a matrix to a data frame**.

```{r prevalencetotal, echo=T, error = TRUE}
prev_current_output <- function() {
  pop_data_mx <- readRDS('../data/population_data_mx.rds')
  set.seed(17)
  daily_survival_rate_males <- daily_survival_rate_current(pop_data_mx, sex = "Males")
  daily_survival_males <- cumprod(1 - daily_survival_rate_males)
  
  daily_survival_rate_females <- daily_survival_rate_current(pop_data_mx, sex = "Females")
  daily_survival_females <- cumprod(1 - daily_survival_rate_females)
  
  registry_years <- c("2004-09-01", "2005-09-01", "2006-09-01", "2007-09-01", "2008-09-01",
                      "2009-09-01", "2010-09-01", "2011-09-01", "2012-09-01", "2013-09-01")
  registry_start_year <- 2
  registry_end_year <- 9
  
  prevalence_total <- prevalence_current(load_data(registry_data), registry_years, registry_start_year, 
                                         registry_end_year, N_years = N_years, 
                                         daily_survival_males = daily_survival_males, 
                                         daily_survival_females = daily_survival_females, 
                                         cure_time = cure*365)
  
  by_year_total <- prevalence_total[[1]]
  by_year_total
}
prev_expected <- prev_current_output()
prev_expected
```

Now let's see what can be improved here...

I'm going to firstly take a brief detour into the `survival` file to update `daily_survival_rate`, as ever I've appended `_dev` to functions that I have modified.

Here is my setup for this debugging.

```{r}
prev_dev <- function() {
  set.seed(17)
  registry_years = sapply(5:13, function(x) sprintf("20%02d-09-01", x))
  prevalence_total <- prevalence_dev(load_data(registry_data), registry_years, 
                                     N_years = N_years, 
                                     cure_time = cure*365)
  by_year_total <- prevalence_total$cases_avg
  by_year_total
}

test_prev <- function() {
  test_vals <- prev_dev()
  if (all(test_vals == prev_expected)) {
    message("Success!")
  } else {
    message("Failure...")
    message("Expected:")
    print(prev_expected)
    message("Actual:") 
    print(test_vals)
  }
}
```

# `daily_survival_rate` modifications:

  + It doesn't appear necessary to pass in the sex selection variable along with the column, just have the user subset the data frame before calling the function. 
  + Rather than coercing the input matrix into a dataframe so that it can be subset more easily, require that the user provide a data frame. If desired can check that if a matrix has been passed to convert into a data frame, but either way the subsetting into genders should be done outside the function.
  + Removed the selecting of the `rate` and `age` columns as holding the other columns doesn't have any impact on how the code runs.
  + Have added a formula interface so that the column names don't need to be hardcoded. Admittedly I don't have much experience with formulae in R and my way of using it may be a bit hacky!
  + Have changed references to the number 100 to a reference to a parameter `max_age`, as I believe this is what it represents
  + Where does the magic number 183 come from?
  + Vectorised the rates calculation from its use of a for loop
  + Removed the last line which only prints out the first index in the output array to screen, but this is never displayed as far as I can see and removing it doesn't seem to have changed the output
  + Combined two simple lines relating to calculating `daily_rate` into one line
  + Included the `cumprod(1-x)` line at the end of the function
  + Renamed function to `population_survival_rate` to better highlight that this calculates based on **population** data rather than the **sample** data
  + Have saved *pop_data-mx* as a data frame rather than a matrix.
  
I've made all these corrections and they haven't affected the prevalence outcome, I'm still getting the correct value as above! (well I was initially anyway, have to take my word for it!)
  
```{r, message=T}
test_prev()
```

# `prevalence`

Now I'll move onto the main function, the `prevalence` code.

Issues:
  + Can refactor all the code which calculates the `post_age_dist` and `by_year` estimates for males and females into a single function and just call it with the relevant parameters for each sex as required
  + As with the `incidence` function, the entire set of registry years do not need to be supplied, only those which are actually used. This removes the `registry_start_year` and `registry_end_year` parameters
  + Should the calculation of `wb` using `survreg` use the full dataset, or just that subset by entering the registry in the years of interest (`data_r`)?
  + Likewise should the calculation of `fix_rate` (**NB: What does this stand for?**) use the full data set (as it currently stands) or `data_r`, which is also used for the prior? The latter makes more sense to me, although it shouldn't matter since the data set gets subset to the registry years when calculating incidence anyway
  + Have renamed `fix_rate` to `known_inc_rate` for clarity (on the output at least)
  + The returned list now has named indices for ease of interpretation
  + Subsetting registry in many different places, i.e. inside `incidence` function, inside `prevalence` into `data_r`. For instance, calling `incidence` on `data` and having this second function form the subsetting when it's been done already in `prevalance` (into `data_r`) is a code smell
  + `type` wasn't correctly determining when a single sex was present in the data frame
  + Have changed the dimensions of the posterior age distribution output from `nyears x nbootstraps x maxyearlyinc` to `nbootstraps x maxyearlyinc x nyears`, primarily because I can't seem to get the list to collapse as desired. If this breaks compatibility with other functions then I should be able to hack a fix, although for the use in histograms etc... it doesn't make a difference
  + Have made the function return an S3 object of class *prevalence*. NB: This is just a glorified list essentially.
  + Have made the population daily survival rates be calculated from within `prevalence` itself, making it more user friendly. The user can specify which population registry to use. The `prevalence` object returns the daily survival rates as item `popsurv`

So now the code is working, however, I'm failing the unit test! **I believe this is because while the new function performs the same role, the ordering has changed, and so the state of the random number generator is not identical to the initial version.** I.e. in the original function the `runif` function would be called twice in succession for both males and females, however, in the latest version, it is called once for males, and then the RNG state is progressed by other draws, so when it's time to draw from `runif` for females, the RNG state is no longer the same. I believe this is why my function produces extremely similar results, but albeit with slightly different values due to the variance.

```{r, message=T}
test_prev()
```

Before I go tinkering with the survival functions, I should check that my program is producing similar results to the original implementation in cases where a single sex is provided.

# Testing over a single sex

Notice that the tests fail, because the expected output is actually the combined output. Showing that the current implementation of the function only works with data sets where both genders are present.

# Refactoring `survival` functions

I imagine that there is some scope to refactor some of the survival operations, so that it isn't necessary to pass in survival functions into the `prevalence` function, and also to speed them up slightly.

Refactoring: 
  + `registry_survival_bootstrapped_dev` has been edited to allow for a formula input, thereby allowing the main `prevalence` function to set the column names. Now the column names aren't hardcoded into this function providing more flexibility.
  + Still wondering why these bootstrapped model coefficients are calculated with just the lower bound of the registry start times and not the upper bound

```{r, message=T}
test_prev()
```

Perfect. The next issue I'd like to work on is getting the daily survival rates to be calculated inside `prevalence` if not provided to facilitate simpler use of the package. I also need to think about how to remove the need for running the data frame through a function to rename the columns. This could prove problematic due to the use of 2 data sets, `registry_data` and `mx_df`, which have different dimensions and it's unclear where they have been derived from or if they are related.

# Speed test

Let's quickly see if these modifications have been any speed changes, here's the current implementation:

```{r}
system.time(prev_current_output())
```

And here's the new one:

```{r}
system.time(prev_dev())
```

No significant speedups there then.

# `counted_prevalence`

Now I'll refactor `counted_prevalence` in the same manner as before. Firstly I'll setup a test function:

```{r}
countprev_current_output <- function() {
  set.seed(17)
  registry_years <- c("2004-09-01", "2005-09-01", "2006-09-01", "2007-09-01", "2008-09-01",
                      "2009-09-01", "2010-09-01", "2011-09-01", "2012-09-01", "2013-09-01")
  registry_start_year <- 2
  registry_end_year <- 9
  
  counted_prevalence_current(load_data(registry_data), registry_years, 
                             registry_start_year, registry_end_year)
}
countprev_expected <- countprev_current_output()
```

```{r}
countprev_dev <- function() {
  set.seed(17)
  registry_years = sapply(5:13, function(x) sprintf("20%02d-09-01", x))
  counted_prevalence_dev(load_data(registry_data), registry_years)
}
```

```{r}
test_countprev <- function() {
  test_vals <- countprev_dev()
  if (all(test_vals == countprev_expected)) {
    message("Success!")
  } else {
    message("Failure...")
    message("Expected:")
    print(countprev_expected)
    message("Actual:") 
    print(test_vals)
  }
}
```

The modifications I've made are:
  + Change the `registry_years` variable so that the start and ending index aren't required to be passed in
  + The code to calculate `per_year` is identical to that in `incidence`, and so this line has been replaced by a function call
  + Have changed the code to calculate the per_year censoring into an sapply to provide encapsulation and better readability
  + No need to subset `registry_years` to those years of interest now that only those years of interest are passed into the function

```{r}
test_countprev()
```

# Speeding up the calculations

Ideally I'd profile the code now but the package which is recommended `lineprof` isn't available for my current R package. I have found a slightly neater way of calculating running time than `System.time` however, using the `microbenchmark` package.
```{r}
library(microbenchmark)
```

Currently the program runs at:
```{r}
microbenchmark(
  prev_dev(),
  times=5
)
```

Median = 11.77 seconds which isn't bad, although it'd be nice if we could get this down to less than 5.

Firstly I'll go through all uses of `sapply` and change to `vapply`, including the main caller of the bootstrap loop.

```{r}
microbenchmark(
  prev_dev(),
  times=5
)
```

11.5 seconds, so a tiny bit saved, although I can imagine the biggest savings will be from having the bootstrapped loop done in C++, so let's try this now. I'll make a file to work on this in called `bootstrap_fit.Rcpp`.

Have made a version of the model fitting procedure which calls the `survreg.fit` function directly with the parameters required to fit a weibull model, rather than the main `survreg` function which does a lot of argument checking and transforms. It also returns a lot of values whereas I'm only interested in the coefficients.
**NB: This speed up is only in the order of magnitude of 0.1 second however! It may just be best to keep the current form as it's more flexible**

I've now made some more changes, after looking what the `survreg.fit` code does and observing that several steps can be moved outside of the main bootstrapping loop without any functional changes. The changes I've made here are:

  + The data is subset into complete cases internally by `survreg.fit`, this does not need to be included inside the bootstrap loop and so has been moved outside
  + Transforming the data frame into a matrix can be moved outside of the bootstrap loop
  + Likewise the log transformation of the output (survival time) 
  + As a result of changing the size of the data matrix which is bootstrapped, the random number generator will sample differently and so the resulting Weibull coefficients will no longer be the exact same as before, although the overall model fit should be very similar
  
These changes produced a reduction in average runtime from 9.5 seconds to 6, which is much better. Ideally this could be further sped up by having the bootstrap loop run inside C++ code, which would then form the bootstrap samples and fit the model, however, `survreg.fit` does a considerable amount of further pre-processing - including producing initial estimates for the coefficients - which would be challenging and time consuming to rewrite into C++ code. If it's decided that further speed ups are necessary then I can look into this in further detail, however for the time being a 50% speed up is pretty good.

```{r}
foo <- function() {
  registry_years = sapply(5:13, function(x) sprintf("20%02d-09-01", x))
  data = load_data(registry_data)
  data$sex <- as.factor(data$sex)
  data_r <- data[data$date_initial >= min(registry_years), ]
  form = Surv(survival_time, indicator) ~ age_initial + sex
  microbenchmark(registry_survival_bootstrapped_dev(form, data, 1000),
                 registry_survival_bootstrapped_direct_dev(form, data, 1000),
                 times=5)
}
foo()
```

Let's also check the output from these functions to confirm they're similar:

```{r}
test_bootstrap <- function(bootstrap_function) {
  registry_years = sapply(5:13, function(x) sprintf("20%02d-09-01", x))
  data = load_data(registry_data)
  data$sex <- as.factor(data$sex)
  data_r <- data[data$date_initial >= min(registry_years), ]
  form = Surv(survival_time, indicator) ~ age_initial + sex
  
  set.seed(3)
  bootstrap_function(form, data, 1000)
}

development_coefs <- test_bootstrap(registry_survival_bootstrapped_dev)
refactored_coefs <- test_bootstrap(registry_survival_bootstrapped_direct_dev)
```

Firstly we can obtain a thousand bootstrapped coefficients for each method, noting that the refactored version runs in around half the time of the original.

Next up I'll compare the two for each coefficient value.
```{r}
development_coefs <- as.data.frame(development_coefs)
colnames(development_coefs) <- c('int', 'age', 'sex', 'scale')
development_coefs$func = 'original'
refactored_coefs <- as.data.frame(refactored_coefs)
colnames(refactored_coefs) <- c('int', 'age', 'sex', 'scale')
refactored_coefs$func = 'refactored'

comparison <- rbind(development_coefs, refactored_coefs)
require(tidyr)
require(ggplot2)
require(dplyr)
comparison %>% gather(coef, val, -func) %>%
    ggplot(aes(x=val, fill=as.factor(func))) +
      geom_histogram(position='identity', alpha=0.7) +
      facet_wrap(~coef, scales = 'free') +
      scale_fill_discrete('Bootstrapping function') +
      labs(x='Coefficient value', y='Count')
```

To me this looks similar enough to warrant using the refactored faster version in place of the original, so I'll go through and make it the default now.
