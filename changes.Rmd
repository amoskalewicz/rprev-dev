---
title: "Changes"
author: "Stuart Lacy"
date: "18 April 2016"
output: 
  html_document: 
    number_sections: yes
    theme: lumen
    toc: yes
    toc_float:
        collapsed: false
    code_folding: show
---

# Introduction

This document lists the changes made to the prevalence code in the current development version, organised by source file. Overall, the changes have improved the codebase's maintainability and readability by removing redundant code and decomposing behaviours into single use functions where possible. Overall runtime has improved as well owing to some tweaking of the bootstrapping Weibull fitting code.

**NB: Required packages aren't being loaded with the package, i.e. `survival` and `dplyr`. The DESCRIPTION file isn't loading them despite listing them as required. Do they need to be told to be explicitly loaded somewhere else, and DEPENDENCIES just lists those which must be installed?**

```{r, message=F, output=F, warning=F}
library(dplyr)
library(abind)
library(rms)
library(survival)
library(devtools)
library(knitr)
library(tidyr)
library(ggplot2)
library(dplyr)
devtools::load_all()
registry_data <- readRDS("data/registry_data.rds")
N_years <- 10
cure <- 3
opts_chunk$set(message=F, warning=F)
```

Rather than using any established unit testing framework, I've just implemented a quick assertation test here that all values in the output are the same (note to self, find out what the best testing framework for R is). This therefore requires the functions under testing to output a vector (rather than a list) to work correctly.

```{r}
test_output <- function(old_func, new_func) {
    expected <- old_func()
    actual <- new_func()
    test <- tryCatch(all(expected == actual),
                     error=function(cond) FALSE)
    if (test) {
        message("Success!")
    } else {
        message("Failure...")
        message("Expected:")
        print(expected)
        message("Actual:") 
        print(actual)
    }
}
```

# `incidence.R`

## `incidence`

Changes here include:

  + Don't need to pass in the whole vector of `registry_years` which aren't used, instead just pass in the the starting registry date to use and the number of years of registry to use
  + Likewise can then calculate the required number of years to be investigated as the length of the passed in vector
  + Don't need to pass in the whole data frame, only the dates of diagnosis are required to calculate incidence, therefore the `load_data` function isn't needed here either
  + Changed the calculation for number of incident events from determining the subset of events in the desired time frame, subsetting the vector with these indices, and then calculating its length, to just calculating the sum of subset of events as it's quicker
  + Changed the for loop into an sapply implementation for readability and encapsulation
  + Removed the storing of the total incident cases in a variable as it's only used once

```{r, echo=T}
inc_test_current <- function () {
  registry_years <- c("2004-09-01", "2005-09-01", "2006-09-01", "2007-09-01", "2008-09-01",
                      "2009-09-01", "2010-09-01", "2011-09-01", "2012-09-01", "2013-09-01")
  registry_start_year <- 2
  registry_end_year <- 9
  incidence_current(load_data(registry_data), registry_years, registry_start_year, 
                    registry_end_year)
}
```

And for the development version...
```{r, echo=T}
inc_test_new <- function() {
  incidence(registry_data$DateOfDiag, start="2005-09-01", num_years=8)
}
```

```{r, message=T}
test_output(inc_test_current, inc_test_new)
```

As can be seen, the same values for incidence rates are calculated.

## `meanIR`

Changes:
  
  + As with `incidence`, removed `registry_year` indices by instead requiring user pass in the starting date and the number of years to use
  + As with `incidence`, the whole registry data frame isn't required to calculate this output, only the entry dates are so the first argument has been changed to a vector
  + A keyword argument has been added to allow the user to select the level of confidence intervals, rather than being hardcoded at 95%
  + Changed the output from a dataframe to a list, since each of the 4 values are not observations of the same variables and are completely independent, therefore a list is a more appropriate data structure. Lists index names are more useful than row names of a data frame too, as the later are generally ignored, while the former lets you index with the familiar *$* syntax.
  + Also have changed the index names for readability (100K vs 100000) and behavioural reasons (having a *-* in a list index is problematic).


```{r}
meanIR_test_curr <- function() {
  registry_years <- c("2004-09-01", "2005-09-01", "2006-09-01", "2007-09-01", "2008-09-01",
                      "2009-09-01", "2010-09-01", "2011-09-01", "2012-09-01", "2013-09-01")
  registry_start_year <- 2
  registry_end_year <- 9
  meanIR_current(load_data(registry_data), registry_years, registry_start_year, 
                 registry_end_year, population_size=3500000)
}
```

```{r}
meanIR_test_dev <- function() {
  meanIR(registry_data$DateOfDiag, population_size=3500000, start='2005-09-01', num_years=8)
}
```

```{r}
test_output(meanIR_test_curr, meanIR_test_dev)
```

The test now fails as the returned objects are no longer comparable due to the dev function returning a list, but if we manually inspect the outputs we can see they are the same. Note that the z values for the confidence intervals are now manually coded and so there may be a slight precision issue, as this is calculated to be `r qnorm(0.975)`, rather than the previously hardcoded 1.96.

# `survival.R`

## `daily_survival_rate()`

Changes:

  + It doesn't appear necessary to pass in the sex selection variable along with the column, just have the user/calling code subset the data frame before calling the function. 
  + Rather than coercing the input matrix into a dataframe so that it can be subset more easily, require that the user provide a data frame. If desired can check that if a matrix has been passed to convert into a data frame, but either way the subsetting into genders should be done outside the function.
  + Have saved *pop_data_mx* as a data frame rather than a matrix to help deal with the above issue.
  + Removed the selecting of the `rate` and `age` columns as keeping the other columns doesn't have any impact on how the code runs.
  + Have added a formula interface so that the column names don't need to be hardcoded. Admittedly I don't have much experience with formulae in R and my way of using it may be a bit hacky!
  + Have changed references to the number 100 to a reference to a parameter `max_age`, as I believe this is what it represents
  + Not a big deal, but 182/183 and 365 should have variable names to indicate they represent the days in 6 months and a year respectively.
  + Vectorised the rates calculation, replacing the for loop
  + Combined two simple lines relating to calculating `daily_rate` into one line
  + Removed the initialisation of `daily_rate` to all 0s as this is overwritten later on
  + Included the `cumprod(1-x)` line at the end of the function
  + Renamed function to `population_survival_rate` to better highlight that this calculates daily survival rates based on **population** data rather than the **sample** data
  
```{r}
current_survival_rates <- function(x) {
  data(population_data_mx_mat)
  daily_survival_rate_males <- daily_survival_rate_current(population_data_mx_mat, sex = "Males")
  daily_survival_males <- cumprod(1 - daily_survival_rate_males)
}
```

```{r}
new_survival_rates <- function(x) {
  data(population_data_mx)
  daily_survival_males <- population_survival_rate(rate ~ age, subset(population_data_mx, sex==0))
}
```

```{r, message=T}
test_output(current_survival_rates, new_survival_rates)
```

As can be seen this produces the same output as before.

## `registry_survival_bootstrapped`

Changes:

  + The function now accepts a formula interface rather than having the variable names hardcoded
  + The for loop has been replaced by a `vapply` in an effort to speed up the run time
  + To fit the Weibull models, `survreg.fit` is called directly rather than `survreg`. This allows the relevant pre-processing steps for a Weibull model to be taken only, as `survreg` is designed to work for a number of distributions. This does limit the flexibility of the package, i.e. if it were decided that a different survival distribution were to be used then this change would need to be reverted, however at the moment it seems a reasonable compromise for the increased run speed
  + The data is subset into complete cases internally by `survreg.fit`, this does not evaluated at each iteration of the bootstrap loop and so has been moved outside
  + Transforming the data frame into a matrix can be moved outside of the bootstrap loop
  + Likewise the log transformation of the output (survival time) 
  + As a result of changing the size of the data matrix which is bootstrapped, the random number generator will sample differently and so the resulting Weibull coefficients will no longer be the exact same as before, although the overall model fit should be very similar
  
We need to confirm that the significant changes to this function still result in similar behaviour, so I'll visualise here the coefficient values from the current bootstrapped implementation as well as the new refactored version.

### Diagnosing coefficients

```{r}
test_bootstrap <- function(bootstrap_function) {
  registry_years = sapply(5:13, function(x) sprintf("20%02d-09-01", x))
  data = load_data(registry_data)
  data$sex <- as.factor(data$sex)
  data_r <- data[data$date_initial >= min(registry_years), ]
  form = Surv(survival_time, indicator) ~ age_initial + sex
  
  set.seed(3)
  
  if (bootstrap_function == 'current') {
    coefs = registry_survival_bootstrapped_current(data, 1000)
  } else {
    coefs = registry_survival_bootstrapped(form, data, 1000)
  }
  coefs
}

current_coefs <- test_bootstrap('current')
new_coefs <- test_bootstrap('new')
```

```{r}
current_coefs <- as.data.frame(current_coefs)
colnames(current_coefs) <- c('int', 'age', 'sex', 'scale')
current_coefs$func = 'original'
new_coefs <- as.data.frame(new_coefs)
colnames(new_coefs) <- c('int', 'age', 'sex', 'scale')
new_coefs$func = 'new'

comparison <- rbind(current_coefs, new_coefs)
comparison %>% gather(coef, val, -func) %>%
    ggplot(aes(x=val, fill=as.factor(func))) +
      geom_histogram(position='identity', alpha=0.7) +
      facet_wrap(~coef, scales = 'free') +
      scale_fill_discrete('Bootstrapping function') +
      labs(x='Coefficient value', y='Count')
```

They look to be similar enough to have the new version replace the old one. The t-tests and K-S tests below indicate there isn't enough evidence to reject the null hypothesis that they're the same at the 5% level.

```{r}
t.test(current_coefs$int, new_coefs$int)
t.test(current_coefs$age, new_coefs$age)
t.test(current_coefs$sex, new_coefs$sex)
t.test(current_coefs$scale, new_coefs$scale)
```

```{r}
ks.test(current_coefs$int, new_coefs$int)
ks.test(current_coefs$age, new_coefs$age)
ks.test(current_coefs$sex, new_coefs$sex)
ks.test(current_coefs$scale, new_coefs$scale)
```


### Runtime speed up

```{r, eval=F}
require(microbenchmark)
runtime_comparison <- function() {
  registry_years = sapply(5:13, function(x) sprintf("20%02d-09-01", x))
  data = load_data(registry_data)
  data$sex <- as.factor(data$sex)
  data_r <- data[data$date_initial >= min(registry_years), ]
  form = Surv(survival_time, indicator) ~ age_initial + sex
  microbenchmark(registry_survival_bootstrapped(form, data, 1000),
                 registry_survival_bootstrapped_current(data, 1000),
                 times=5)
}
runtime_comparison()
```

As can be seen, the speed up resulting from these changes is substantial.

# `prevalence.R`

## `prevalence`

Changes:

  + The main change is that this large function has been refactored into several smaller functions, allowing for improved readability and maintainability
  + Have refactored all the code which calculates the `post_age_dist` and `by_year` estimates for males and females into a single function and just call it with the relevant parameters for each sex as required
  + Rather than requiring a data frame with the correctly specified column names, the function now accepts a formula
  + The code previously didn't correctly work when datasets with a single sex were passed in. This has been fixed.
  + Have made the function return an S3 object of class *prevalence*. NB: This is just a glorified list essentially, but is more in the style of idiomatic R and allows for simpler indexing.
  + Have made the population daily survival rates be calculated from within `prevalence` itself, making it more user friendly. The user can specify which population registry to use. The `prevalence` object returns the daily survival rates as item `popsurv`
  + Have changed the dimensions of the posterior age distribution output from `nyears x nbootstraps x maxyearlyinc` to `nbootstraps x maxyearlyinc x nyears`, primarily because I can't seem to get the list to collapse as desired. If this breaks compatibility with other functions then I should be able to hack a fix, although for the use in histograms etc... it doesn't make a difference
  + As with the `incidence` function, the entire set of registry years do not need to be supplied, instead the user just enters the registry date of interest and the number of years to use
  + Should the calculation of `wb` using `survreg` use the full dataset, or just that subset by entering the registry in the years of interest (`data_r`)?
  + Have renamed `fix_rate` to `known_inc_rate` for clarity (on the output at least)
  + Changed the calculation of average `by_year_cases` from an `apply(foo, 1, mean)` call to `rowMeans` as it's quicker and more readable
  
### Diagnosing function

Since the order in which the RNG is called has been changed, the results from the refactored function won't be **exactly** the same as the old ones, and so a unit test will fail here. However, we can compare them to observe if they are similar enough and only differ due to random variance.


```{r}
prev_current_output <- function() {
  data(population_data_mx_mat)
  set.seed(17)
  daily_survival_rate_males <- daily_survival_rate_current(population_data_mx_mat, sex = "Males")
  daily_survival_males <- cumprod(1 - daily_survival_rate_males)
  
  daily_survival_rate_females <- daily_survival_rate_current(population_data_mx_mat, sex = "Females")
  daily_survival_females <- cumprod(1 - daily_survival_rate_females)
  
  registry_years <- c("2004-09-01", "2005-09-01", "2006-09-01", "2007-09-01", "2008-09-01",
                      "2009-09-01", "2010-09-01", "2011-09-01", "2012-09-01", "2013-09-01")
  registry_start_year <- 2
  registry_end_year <- 9
  N_years = 10
  
  prevalence_current(load_data(registry_data), registry_years, registry_start_year, 
                     registry_end_year, N_years = N_years, 
                     daily_survival_males = daily_survival_males, 
                     daily_survival_females = daily_survival_females, 
                     cure_time = cure*365)
}
```

```{r}
prev_dev <- function() {
  set.seed(17)
  N_years = 10
  prevalence(Surv(stime, status) ~ sex(sex) + age(age) + entry(DateOfDiag),
             registry_data, N_years = N_year,
             start='2005-09-01', num_years=8,
             cure_time = cure*365)
}
```

```{r}
prev_male <- function() {
  set.seed(17)
  N_years = 10
  prevalence(Surv(stime, status) ~ sex(sex) + age(age) + entry(DateOfDiag),
             subset(registry_data, sex==0), N_years = N_year,
             start='2005-09-01', num_years=8,
             cure_time = cure*365)
}
```

Just comparing the function calls shows how much the refactored version has been simplified, with 4 fewer parameters.

I'll compare the functions on their average predicted prevalence rates.

```{r, message=T}
test_output(function() prev_current_output()[[1]], 
            function() prev_dev()$cases_avg)
```

This indicates that while the exact same average predicted prevalence rates aren't being calculated, but they are similar enough. 

#### Prevalence distribution

And can also look at their distributions (each year is in a separate frame):

```{r}
f_cur <- prev_current_output()
f_dev <- prev_dev()
cases_curr <- data.frame(lapply(setNames(seq(dim(f_cur[[3]])[1]), seq(dim(f_cur[[3]])[1])), 
                                function(x) f_cur[[3]][x, ]),
                         method='current')
cases_dev <- data.frame(lapply(setNames(seq(dim(f_dev$cases_total)[1]), seq(dim(f_dev$cases_total)[1])), 
                               function(x) f_dev$cases_total[x, ]),
                        method='new')
cases_comb <- rbind(cases_curr, cases_dev)

cases_comb %>% 
  gather(year, cases, -method) %>%
  ggplot(aes(x=cases, fill=method)) +
    geom_histogram(alpha=0.7, position='identity') +
    facet_wrap(~year, scales='free') +
    scale_fill_discrete('Prevalence Function') +
    labs(x='Cases', y='Count')
```

```{r}
year_names = names(dplyr::select(cases_curr, -method))
lapply(setNames(year_names, year_names), function(x) t.test(cases_curr[, x], cases_dev[, x])$p.value)
lapply(setNames(year_names, year_names), function(x) ks.test(cases_curr[, x], cases_dev[, x])$p.value)
```

**NB: I'm not trying to show the pattern of the predicted prevalence over time, but rather show that the values estimated by the refactored version of the `prevalence` function is consistent with the previous results.**

It is surprising how similar the distributions here, even down to both having noticeable valleys in some years (7, 5 and 9) at the same number of cases. To me, this indicates this refactored version is predicting prevalence consistently with the original implementation.

There are a few low p-values from the t-test here, particularly at years 1 (p < 0.05) and also 5 and 6. Looking at the distribution of these years, the distributions look to be very similar with little observable difference in the shape or spread (no obvious outliers). If anything I'd expect a difference in p-values in years 3 and 4 as the distribution around the median looks slightly different here.

The K-S tests show no significant difference in the distributions of the prevalent cases.

#### Posterior age distribution

Another diagnostic is looking at the posterior age distributions of the people alive (is this what $post returns?).

The plot below indicates they are extremely similar, and so it doesn't seem worthwhile running a significance test on it.

```{r, message=F, warning=F}
post_cmp <- data.frame(age=c(as.vector(f_cur[[2]]), as.vector(f_dev$post)),
                       method=rep(c('current', 'dev'), c(length(f_cur[[2]]), length(f_dev$post))))
ggplot(post_cmp, aes(age, fill=method)) +
    geom_histogram(position='identity', alpha=0.7) +
    scale_fill_discrete("prevalence version") +
    labs(x="Age", y="Count")
```

## `counted_prevalence`

Changes:

  + Change the `registry_years` variable so that the start and ending index aren't required to be passed in
  + The code to calculate `per_year` is identical to that in `incidence`, and so this line has been replaced by a function call
  + Have changed the code to calculate the per_year censoring into an sapply to provide encapsulation and better readability
  + No need to subset `registry_years` to those years of interest now that only those years of interest are passed into the function
  + The user just needs to pass in two columns, the status_at_index and the entry_date column rather than the full data frame
  
  
```{r}
countprev_current_output <- function() {
  registry_years <- c("2004-09-01", "2005-09-01", "2006-09-01", "2007-09-01", "2008-09-01",
                      "2009-09-01", "2010-09-01", "2011-09-01", "2012-09-01", "2013-09-01")
  registry_start_year <- 2
  registry_end_year <- 9
  
  counted_prevalence_current(load_data(registry_data), registry_years, 
                             registry_start_year, registry_end_year)
}
```

```{r}
countprev_dev <- function() {
  counted_prevalence(registry_data$DateOfDiag, registry_data$status2, start='2005-09-01', num_years=8)
}
```

```{r, message=T}
test_output(countprev_current_output, countprev_dev)
```

## `N_year_estimates`

Changes:

  + Removed both `registry_start_year` and `registry_end_year` in place of a single integer representing the number of years used in the registry
  + Added an argument for the user to specify the confidence interval level (it's currently hardcoded at 1.96)
  + Changed the output format to a list with 4 objects with the raw estimate, and the proportion per 100K with lower and upper bounds, to be consistent with `meanIR` output. Also outputting the values as `numeric` rather than `strings` is much more user friendly, allowing them to be plotted or stored.
  + Likewise added a keyword argument for the user to specify the level of precision, as with `meanIR`
  + Refactored the duplicated code calculating the SE, so that the condition on num_reg_years < N_year now only calculates the differing standard errors, as this is more precisely the behaviour defined by the condition
  + Removed the use of the *<<-* operator, as I can't see the benefits of looking for a variable with this name in a higher scope

```{r}
nyear_test_curr <- function() {
  prevalence_curr <- prev_current_output()
  by_year_samples_total <- prevalence_curr[[3]]
  by_year_total <- prevalence_curr[[1]]
  registry_start_year = 2
  registry_end_year = 9
  
  n_year_estimates_current(N_years = 3, registry_start_year = registry_start_year, 
                           registry_end_year = registry_end_year, 
                           the_samples = by_year_samples_total, by_year = by_year_total,
                           population_size = 3500000)
    
}
```

```{r}
nyear_test_dev <- function() {
  prevalence_d <- prev_dev()
  n_year_estimates(N_years = 3, num_reg_years=8,
                       the_samples = prevalence_d$cases_total, 
                       by_year = prevalence_d$cases_avg,
                       population_size = 3500000)
}
```

As expected the test fails as the outputs are lists, however, manual inspection demonstrates that they are calculating the same values (given the minor variation in the prevalence calculations).

```{r}
test_output(nyear_test_curr, nyear_test_dev)
```



## `prevalence_by_age`

Changes:

  - Changed the indexing the of the 3D posterior distribution array, since the dimensions have changed order from the latest version of `prev`.
  - Changed the hardcoded age binning into a parameter, which by default is by decade, although the user can specify whatever interval they want
  - Removed a redundant `unlist()` command

```{r}
prevage_test_curr <- function() {
    prev_obj <- prev_current_output()
    post_age_dist_total <- prev_obj[[2]]
    registry_end_year = 9
    N_years = 10
    prevalence_by_age_current(dist = post_age_dist_total, registry_end_year, N_years)
}
```

```{r}
prevage_test_dev <- function() {
    prev_obj <- prev_dev()
    prevalence_by_age(prev_obj)
}
```

```{r}
test_output(prevage_test_curr, prevage_test_dev)
```

As expected, the values are no longer identical but they are close enough to demonstrate the function is calculating the same thing as before.

Note the new behaviour of the function, the user can specify the age bins with the provided parameter. Here the user is interested in segmenting the distribution into 4, 0-18, 18-50, 50-80, and >80.

```{r}
prev_obj <- prev_dev()
prevalence_by_age(prev_obj, age_intervals=c(18, 50, 80))
```

# Utility Functions

I've also added in `print` and `summary` methods for the `prevalence` object, found in `utils.R`.

```{r}
obj <- prev_dev()
print(obj)
```

```{r}
summary(obj)
```

# Debugging NLPHL data

```{r}
test_nlphl <- function() {
    prelim <- read.csv("R:/HMRN/Substudies/Prevalence/20140402_Prevalence_All/NLPHL/20140414_NLPHL_all.csv", header=T)
    prelim$DateOfDiag <- as.Date(prelim$DateOfDiag, format="%d/%m/%Y")
    prelim$EventDate <- as.Date(prelim$EventDate, format="%d/%m/%Y")
    prelim$stime <- as.double(difftime(prelim$EventDate, prelim$DateOfDiag, units="days"))
    prelim$stime <- ifelse(prelim$stime <= 0, 1, prelim$stime) 
    prelim <- prelim[!is.na(prelim$sex), ]
    prelim_r <- prelim[prelim$DateOfDiag >= "2006-09-01", ]
    
    N_years <- 10
    names <- list(age='age', status='status', entry_date='DateOfDiag', sex='sex', time='stime')
    cure <- 3
    
    set.seed(17)
    
    prevalence(Surv(stime, status) ~ sex(sex) + age(age) + entry(DateOfDiag),
               prelim_r, start='2007-09-01', num_years=8,
               N_years = N_years,
               cure_time = cure*365)
}
```

```{r}
foo <- test_nlphl()
foo
```

I've made several changes to the code to get the algorithm working with the NLPHL dataset, acting as an example dataset where there are very few events, and so the fit found by the Weibull model may not be ideal.

  + When the initial bootstrapped coefficients are determined, appropriate error handling determines if there has been an error in this procedure rather than crashing the program
  + If any of the following conditions are found for a bootstrapped sample, then a new set of coefficients are produced. This is continued until all the sets of coefficients are *clean*
    + If any of the coefficients are `NA`
    + If any of the coefficients are `NaN`
    + If the raw shape parameter is > 100, as this leads to large values when calculating exp(shape) which is the parameterisation used in the survival probability calculation
  + Another state which can cause the program to crash is when the `scale` (`exp(beta*X)`) parameter is 0, `pweibull` returns `NaN`. Since this parameter is a function of the co-variates, it is hard to determine precisely what values of beta are too large when these are calculated during the bootstrapping phase, so instead when the survival probabilities are calculated a small value (0.000001) is added to `scale` to ensure that a probability in [0,1] is returned.
  + The `prevalence` function also returns a warning to the user if there are any issues with the coefficients during this bootstrapping, which along with the warnings thrown from `survfit` about the function not converging, should alert the user to the fact that there are complications with their data set
  
As can be seen below, these changes haven't affected the performance when using a larger data set with more events.

```{r}
bar <- prev_dev()
bar
```

# Further Work

There are still several areas that can be improved:

  + Are there any actual differences between population_data and population_data_mx?
  + It could be worth further optimising the bootstrapping function, although this would be challenging as it would require the pre-processing currently done in `survreg.fit` to be implemented in C++. Maybe just parallelise it instead?
  + The package doesn't load dependent libraries (such as survival, dplyr etc...), despite being listed in the DESCRIPTION file. Is there another file where libraries to be loaded should be specified?
  + Improve the `print` and `summary` methods of `prevalence` after receiving feedback
  + I haven't looked at the functions in `diagnostics.R` yet
