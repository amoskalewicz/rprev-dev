---
title: "Comparison of v0.3"
output:
    html_notebook:
        toc: true
        toc_float: 
            collapsed: false
---

```{r, echo=F}
library(flexsurvcure)
library(RODBC)
library(dplyr)
library(ggplot2)
library(RODBC)
library(tidyr)
devtools::load_all()
data(prevsim)
```

# Introduction

In the [previous notebook](rprev_newversion.html), I introduced the new parameterisation and backend simulation approach of the new rprev version (v0.3) and provided a small demonstration between the two, suggesting that both methods produce similar estimates. This notebook extends this to include the latest features that I've added, comprising incidence modelling, accepting custom survival models, and the cure model implementation in v0.3, which borrows heavily from the `flexsurvcure` package using mixture models, rather than the custom method used previously.

# Cure model

## Background

A quick introduction to the mixture cure model then. Essentially this model assumes that there is a certain fraction of the population that are cured of the disease, and attempts to model both the survival function of the cured individuals, and also model the probability of being cured.

$S(t|x) = S_{c}(t|x)(1 - \pi(x) + \pi(x)S_{u}(t | x))$

Where $\pi(x)$ is the probability of being **uncured** for a patient with covariates $x$, and is typically modelled as a logistic regression. $S_{u}(t|x)$ is the survival function that will typically come from an appropriate distribution, while $S_{c}(t|x)$ represents the survival function for cured patients, and can be estimated from population mortality tables.

There are also *non-mixture* cure models but I haven't looked into this at all.

## Implementation

The package `flexsurvcure` extends the (already fantastic) `flexsurv` with cure models with a user-friendly API, as shown below. The new arguments here are `link` and `mixture`. `link` specifies the transform to use on $\pi(x)$, while the `mixture` flag indicates whether the model should be a mixture or non-mixture.

```{r}
cure_mod <- flexsurvcure(Surv(time, status) ~ age + sex, data=prevsim, dist='weibull', link='logistic', mixture=TRUE)
```

Before going into the interpretation of the model coefficients, it's important to point out how the these models are parameterised by `flexsurvcure`. By default, the covariates specified on the RHS of the formula are solely acting on $\pi(x)$, and have no effect on the survival function, i.e. modelling

$S(t|x) = S_{c}(t|x)(1 - \pi(x) + \pi(x)S_{u}(t))$

It is possible to specify that covariates should also impact on the survival function but I am not familiar enough with cure models to suggest whether this is always appropriate so for now I've been using the default parameterisation.

The model as displayed below then has the following interpretation:

  - `theta`: The intercept of a logistic regression on whether a patient is **uncured** or not.
  - `sexF`: The effect of sex on the log-odds of a patient being uncured
  - `age`:  The effect of age on the log-odds of a patient being uncured
  - `shape`: The shape of the Weibull distribution giving the survival function of uncured patients. Note that since the package is based on top of `flexsurv` it uses the same distribution parameterisations as the ones in R (i.e. `pweibull`, `rweibull`, ...) rather than the ones used in the `survival` package
  - `scale`: The scale of the Weibull distribution
  
**Note that this is a simulated data set and so a cure model may not be appropriate at all. This is just an example of the implementation**. This shows that elderly patients are more likely to not be cured, while the effect of sex on cure probability is inconclusive.

```{r, echo=F}
cure_mod
```

I personally couldn't follow how the models would be able to fit well if the covariate effects were only placed on the logistic regression so I plotted the Kaplan-Meier (directly below) along with the estimated survival function for an average age male and female from the mixture cure model (below the K-M). The model does seem to fit well, although I'd like to look a little more closely at how the covariate effects are handled.

```{r}
ecsgR::ggkm(survfit(Surv(time, status) ~ sex, prevsim))
```

```{r, echo=F}
cure_surv_probs <- summary(cure_mod, newdata=data.frame(sex=factor(c('F', 'M'), levels=c('F', 'M')), age=mean(prevsim$age)), t=1:4000, tidy=T)
cure_surv_probs$sex <- factor(cure_surv_probs$sex, levels=c('F', 'M'))
ggplot(cure_surv_probs, aes(x=time, y=est, colour=sex)) +
    geom_line() +
    ylim(0, 1) +
    labs(x="Time (days)", y="Survival Probability") +
    ecsgR::theme_Publication() +
    ecsgR::scale_colour_Publication()
```

## Covariate effects on survival function

I'm curious if the location of the covariate effects in the cure model makes a difference on the model's survival estimates. The default parameterisation as shown above has the predictors **solely** affecting the probability of being cured, rather than the survival function itself.

However, upon trying this myself through the use of the `anc` argument, the optimisation won't converge. **I'd like to look more into this, and get feedback from others on whether it's worth trying to get this to work or just stick with the default of covariates acting on $\pi(x)$.**

```{r}
cure_mod_anc <- flexsurvcure(Surv(time, status) ~ age + sex, data=prevsim, dist='weibull', 
                             anc=list(scale=~ age + sex), link='logistic', mixture=TRUE)
```

# Comparison of prevalence estimates on simulated data

This section provides a quick summary of the new prevalence function, comparing it to the old version using both cure models and not, as well as brief look at using different distributions for the survival function. The comparison is carried out on the `prevsim` simulated data set that is supplied with `rprev`.

## No cure model

The function calls below show that, in my opinion, the new version is cleaner and better separates the prevalence into its 2 constituent stochastic processes. Here is the old version:

```{r}
wei_legacy_nocure <- prevalence_legacy(Surv(time, status) ~ age(age) + sex(sex) + entry(entrydate) + event(eventdate),
                                       data=prevsim, 
                                       num_years_to_estimate = c(5, 10, 20, 50), 
                                       num_reg_years = 10,
                                       population_size = 1e6, 
                                       cure = 9999,
                                       index_date = '2013-01-01')
```

The new parameterisation shown below highlights the incidence and survival models as separate processes. The default Incidence model (a homogeneous Poisson process) is controlled by a formula `inc_formula`, with the LHS providing the incident date column name; the RHS specifies any categorical variables to stratify by. In this case we are stratifying incidence by sex, although it is not obligatory to provide a stratification variable, instead passing `entrydate ~ 1`.

```{r}
wei_new_nocure <- prevalence(index='2013-01-01', 
                             num_years_to_estimate=c(5, 10, 20, 50), 
                             data=prevsim, 
                             inc_formula = entrydate ~ sex,
                             surv_formula = Surv(time, status) ~ age + sex, 
                             population_size = 1e6,
                             dist='weibull', 
                             death_column = 'eventdate')
```

Prevalence has been estimated over a number of years, using the same Weibull survival model for both with just age and sex as covariates, and a homogeneous Poisson process for incidence stratified by sex. The prevalence estimates are extremely similar, even when simulating 50 years back, suggesting that the new version is well calibrated.

```{r}
wei_legacy_nocure
```

```{r}
wei_new_nocure
```

## With cure model

However, a more interesting comparison is in the prevalence estimates when using a cure model for estimating the survival function. This is no longer just testing a different software implementation of the same mathematical model, but also a different underlying model. The *legacy* cure model adds on the population survival function after a set threshold of years when the patient is deemed to be cured of the disease. This necessitates a priori knowledge of an appropriate cure time. The new method uses the established mixture model, which assumes that the patient population consists of a subset of individuals who are cured and have population mortality. We wouldn't therefore expect these two approaches to provide the same prevalence estimates, although it will be interesting to see how they compare.

**NB: one practical drawback of the mixture cure model is its extremely long fitting time, as I assume it is using EM to fit the latent $\pi(x)$ model. This means the overall prevalence estimation using 1000 simulations is an order of magnitude slower and so for a start could not be used for our website prevalence estimation.**

```{r}
wei_legacy_cure <- prevalence_legacy(Surv(time, status) ~ age(age) + sex(sex) + entry(entrydate) + event(eventdate),
                                     data=prevsim, 
                                     num_years_to_estimate = c(5, 10, 20, 50), 
                                     num_reg_years = 10,
                                     population_size = 1e6, 
                                     cure = 10,
                                     index_date = '2013-01-01')
```

**Note that I had to reduce the number of simulations here to 100, and even then it still took a few minutes.** I'll also explain the `surv_model` argument later.

```{r}
wei_new_cure <- prevalence(index='2013-01-01', 
                           num_years_to_estimate=c(5, 10, 20, 50), 
                           data=prevsim, 
                           inc_formula = entrydate ~ sex,
                           surv_model = cure_mod, 
                           population_size = 1e6,
                           death_column = 'eventdate', 
                           N_boot = 100)
```

```{r}
wei_legacy_cure
```

The mixture cure model is more optimistic about the overall survival of cured patients, or predicts a very high proportion will be cured, since the prevalence is significantly higher than the non-cure model 50-year estimate of 1,040. Is this difference too large, or can it be justified? I need to read up more on mixture cure models. The old cure model method actually gives counter-intuitive results since the cure model results in a **decrease** in prevalence, while the mixture model **increases** prevalence, as would be expected since population survival is (assumedly) higher than that from the disease.

```{r}
wei_new_cure
```

## Different distributions

With the new implementation it is now easy to provide different distributions for the survival model, below we can see that the Weibull, Log-normal, and Exponential distributions offer a range of prevalence estimates so care must be taken to provide a sensible model.

```{r}
prevalence(index='2013-01-01', num_years_to_estimate=c(10, 20, 50), data=prevsim, 
           inc_formula=entrydate ~ sex,
           surv_formula = Surv(time, status) ~ age + sex, population_size = 1e6,
           dist='weibull', death_column="eventdate")
```

```{r}
prevalence(index='2013-01-01', num_years_to_estimate=c(10, 20, 50), data=prevsim, 
           inc_formula=entrydate ~ sex,
           surv_formula = Surv(time, status) ~ age + sex, population_size = 1e6,
           dist='lognormal', death_column = "eventdate")
```


```{r}
prevalence(index='2013-01-01', num_years_to_estimate=c(10, 20, 50), data=prevsim, 
           inc_formula=entrydate ~ sex,
           surv_formula = Surv(time, status) ~ age + sex, population_size = 1e6,
           dist='exponential', death_column = "eventdate")
```

## Passing in custom survival objects

Specifying the survival model in terms of its formula and distribution uses a custom, optimised implementation of the `survreg` call. I've currently only got it working for the three distributions above, but I hope to extend it to other ones later on.

**However,** users aren't limited to these 3 distributions. I've also added a method for `flexsurvreg` objects, which allows any object created from `flexsurv` to be passed in. This approach is slower than my optimised methods, but for users with specific needs this provides greater flexibility. 

For example, if I want a log-logistic survival model then I can pass one in through the `surv_model` argument instead, as follows.

```{r}
llogis_mod <- flexsurvreg(Surv(time, status) ~ sex + age, data=prevsim, dist='llogis')
llogis_mod
```

This creates the survival object in a familiar way, then it can be directly passed into the `prevalence` call. This allows for the user to do the model selection and diagnostics in their familiar environment and pass the final model directly into `rprev`. This is far slower than the default method, but if the `rprev` step is only run once at the end of the model building stage then this shouldn't be a big drawback given the increased flexibility this option provides. 

Note that I've had to reduce it to 100 simulations to get it to run so I can finish up quickly and go on holiday and this took several minutes. I'll do a formal speed comparison when I get back.

```{r}
prevalence(index='2013-01-01', num_years_to_estimate=c(10, 20, 50), data=prevsim, 
           inc_formula=entrydate ~ sex,
           surv_model=llogis_mod, population_size = 1e6,
           death_column = "eventdate",
           N_boot=100)
```

# Cure model comparison on AML

The comparison of the old cure model and the mixture model on the simulated data highlighted a significant difference in how the cure models affect prevalence. The old implementation actually reduced prevalence, indicating that population survival is worse than survival from the diesease (50-year prevalence decrease from 1,040 to 936), which is rather counter-intuitive. The mixture cure model had the opposite affect, with prevalence increasing (50-year prevalence increased from 1,040 to 1,267).

However, comparing these models on a simulated dataset isn't a fair way of assessing the validity of the cure model, since this data set has not been generated with a group of cured patients in mind. This section instead compares these two models on a real-world data set in which a cure model has empirical justification. 

## Data

The data set in particular is Acute Myeloid Leukaemia (AML). Survival in AML has been observed to follow a bi-modal distribution, with many people experiencing rapid fatility, but with a second group of individuals experiencing long-term survival, as if they have been entirely cured of the disease with their survival being instead modelled by a different process. A mixture model is therefore an appropriate analysis tool for this data set.

For this analysis I'll just be using age and sex to model survival.

```{r, echo=F}
cx <- odbcConnect("HMRN")
aml <- sqlQuery(cx, query="SELECT sex=Sex, age=AgeDiagnosis, DateOfDiag, EventDate, EventType FROM Source.data.Subjects WHERE DiagnosticGroupWHO = 'Acute myeloid leukaemia'")
odbcClose(cx)  
aml$stime <- as.numeric(difftime(aml$EventDate, aml$DateOfDiag, units='days'))
aml$status <- as.numeric(aml$EventType == 'D')
aml[is.na(aml$status), 'status'] <- 0
aml <- aml %>%
            select(sex, age, stime, status, DateOfDiag, EventDate)
aml[aml$stime <= 0, 'stime'] <- 1
```

```{r, echo=F}
aml
```

The Kaplan-Meier curve shows that the majority of patients have a very poor prognosis with 75% of them having died within 1.5 years. The events trail off after this time-points, indicating a significant number of long-term survivors. It is hoped that the cure models are able to capture this phenomenon.

```{r, echo=F}
ecsgR::ggkm(survfit(Surv(stime, status) ~ 1, data=aml))
```

## Prevalence modelling

AML prevalence will be modelled across a number of years to identify two things:

  1. Whether the survival models are able to adequately the survival process of patients diagnosed with AML
  2. The impact of the cure model implementation (old vs mixture)
  
### Without cure model

I'll firstly confirm that the old and new `rprev` implementations produce similar prevalence estimates when not using a cure model and the same parameteric family for the survival model. This should be the case, as they will be using identical parameterisations for the incidence model and the only difference in the survival model is in how the interface to `survreg.fit` is coded.

```{r}
old_aml_nocure <- prevalence_legacy(Surv(stime, status) ~ age(age) + sex(sex) + entry(DateOfDiag) + event(EventDate),
                                    data=aml, 
                                    num_years_to_estimate = c(5, 10, 20, 50), 
                                    num_reg_years = 11,
                                    population_size = 1e6, 
                                    cure = 9999,
                                    index_date = '2015-09-01')
```

```{r}
new_aml_nocure <- prevalence(index='2015-09-01', 
                             num_years_to_estimate=c(5, 10, 20, 50), 
                             data=aml, 
                             inc_formula = DateOfDiag ~ sex,
                             surv_formula = Surv(stime, status) ~ age + sex, 
                             population_size = 1e6,
                             dist='weibull', 
                             death_column = 'EventDate')
```

Yes, these implementations give extremely similar results. They aren't expected to be identical since the old method uses a discrete number of registry years (11 in this case), while the new method working on a day time-scale uses the maximum number of full days available.

```{r}
old_aml_nocure
```

```{r}
new_aml_nocure
```

I'll quickly look at the predicted survival curve of an 'average' person and compare it to the Kaplan-Meier to see how well the rapid fatility and long term surviror aspect of AML is modelled by the Weibull distribution. This example also how demonstrates the user-friendliness of the new parameterisation, since this calculation only involves taking the returned survival object and calling a method on it.

```{r}
pred_surv <- predict_survival_probability(new_aml_nocure$surv_model, 
                                          newdata=data.frame(age=rep(mean(aml$age), 4611), 
                                                             sex=factor(rep('M', 4611), levels=levels(aml$sex))),
                                          times = 1:4611)
```

This figure below demonstrates that the Weibull model (in red) doesn't quite capture that there is a significant portion of long-term survivors in the AML cohort.

```{r, echo=F}
ecsgR::ggkm(survfit(Surv(stime, status) ~ 1, aml)) +
    geom_line(data=data.frame(s=pred_surv, t=1:4611), aes(x=t, y=s), colour='red')
```

### With cure models

A cure model is not only a plausible model for the AML data set (as a minority of long-term survivors have been observed), but also can provide more accurate prevalence estiamtes.

I'll firstly build a legacy cure model. Looking at the Kaplan-Meier a cure model of 3 years seems plausible:

```{r}
old_aml_cure <- prevalence_legacy(Surv(stime, status) ~ age(age) + sex(sex) + entry(DateOfDiag) + event(EventDate),
                                  data=aml, 
                                  num_years_to_estimate = c(5, 10, 20, 50), 
                                  num_reg_years = 11,
                                  population_size = 1e6, 
                                  cure = 3*365.25,
                                  index_date = '2015-09-01')
```

Note that this has some trouble converging, similar to how the legacy method struggled. I imagine this is due to a lack of events at later times.

```{r}
aml_cure_mod <- flexsurvcure(Surv(stime, status) ~ age + sex, data=aml, 
                             dist='weibull', link='logistic', mixture=TRUE)
aml_cure_mod
```

As before, we simply pass this object into the `prevalence` call. Again, I'll use 100 bootstraps so that the runtime isn't too long. However, note that due to repeating the above `flexsurvcure` call 100 times, there are a lot of `NaN` warnings. It would be useful to understand whether these hinder the prevalence estimations. If we were interesting in understanding AML and wanted an accurate model then we'd unfortunately most likely have to conclude that we don't have sufficient data to use `flexsurvcure`, either on its own or in `rprev`.

```{r}
new_aml_cure <- prevalence(index='2015-09-01', 
                           num_years_to_estimate=c(5, 10, 20, 50), 
                           data=aml, 
                           inc_formula = DateOfDiag ~ sex,
                           surv_model = aml_cure_mod,
                           population_size = 1e6,
                           death_column = 'EventDate',
                           N_boot = 100)
```

Remembering that the non-cure model had a 50-year prevalence of ~543 from both implementations and we can see that the same pattern as seen on the simulated data set has arisen: the mixture cure model drastically increases long-term survival while there is less of an effect from the legacy cure model, but it seems to reduce survivability.

```{r}
old_aml_cure
```

```{r}
new_aml_cure
```

This is quite a significant increase in prevalence, from 540 to 840 in a population area of 3 million. I'll plot the survival function for an average age male and see how this compares to both the non-cure model and the Kaplan-Meier. It is unfortunately hard to plot the survival function of the legacy cure model and so this won't be considered here.

The figure below highlights that the cure model is better able to predict survival in long-term survivors than the non-cure model, but although it is has a worse fit up to around 5 years.

```{r, echo=F}
pred_surv_cure <- predict_survival_probability(new_aml_cure$surv_model, 
                                               newdata=data.frame(age=rep(mean(aml$age), 4611), 
                                                                  sex=factor(rep('M', 4611), levels=levels(aml$sex))),
                                               t=1:4611)
surv_pred_comb <- data.frame(nocure = pred_surv, cure=pred_surv_cure, t=1:4611) %>%
                    gather(method, surv, -t)

ecsgR::ggkm(survfit(Surv(stime, status) ~ 1, aml)) +
    geom_line(data=surv_pred_comb, aes(x=t, y=surv, colour=method)) +
    ecsgR::scale_colour_HMRN("Model")
```

# Speed comparison

Before I went on holiday I'd noticed that the full cure model was significantly slower, although due to the large runtime of it I was unable to run a full comparison with the legacy cure model. I'll now do this, to highlight that using a full simulation of the cure model would pose problematic for regular use, for example in our website estimations, although one off calculations such as for publications should be fine.

```{r, echo=F}
legacy_speed <- system.time(prevalence_legacy(Surv(stime, status) ~ age(age) + sex(sex) + entry(DateOfDiag) + event(EventDate),
                                              data=aml, 
                                              num_years_to_estimate = c(5, 10, 20, 50), 
                                              num_reg_years = 11,
                                              population_size = 1e6, 
                                              cure = 9999,
                                              index_date = '2015-09-01'))
```

```{r, echo=F}
legacy_cure_speed <- system.time(prevalence_legacy(Surv(stime, status) ~ age(age) + sex(sex) + entry(DateOfDiag) + event(EventDate),
                                              data=aml, 
                                              num_years_to_estimate = c(5, 10, 20, 50), 
                                              num_reg_years = 11,
                                              population_size = 1e6, 
                                              cure = 3*365.25,
                                              index_date = '2015-09-01'))
```

```{r, echo=F}
new_speed <- system.time(prevalence(index='2015-09-01', 
                             num_years_to_estimate=c(5, 10, 20, 50), 
                             data=aml, 
                             inc_formula = DateOfDiag ~ sex,
                             surv_formula = Surv(stime, status) ~ age + sex, 
                             population_size = 1e6,
                             dist='weibull', 
                             death_column = 'EventDate'))
```

```{r, echo=F}
new_flex_speed <- system.time(prevalence(index='2015-09-01', 
                             num_years_to_estimate=c(5, 10, 20, 50), 
                             data=aml, 
                             inc_formula = DateOfDiag ~ sex,
                             surv_model=flexsurvreg(Surv(stime, status) ~ sex + age, data=aml, dist='weibull'),
                             population_size = 1e6,
                             death_column = 'EventDate'))
```

```{r, echo=F}
new_cure_speed <- system.time(prevalence(index='2015-09-01', 
                             num_years_to_estimate=c(5, 10, 20, 50), 
                             data=aml, 
                             inc_formula = DateOfDiag ~ sex,
                             surv_model=flexsurvcure(Surv(stime, status) ~ age + sex, data=aml, 
                                                     dist='weibull', link='logistic', mixture=TRUE),
                             population_size = 1e6,
                             death_column = 'EventDate'))
```

The table below shows the runtimes for each of these prevalence estimation implementations on the AML dataset with 1,000 bootstrap samples. Note that these are all run **on a single core**, although the legacy code has support for multi-core execution while the new method doesn't as of yet. As expected the legacy code is the quickest, with the cure model not adding any additional computational demands. The default new implementation is only slightly slower however, and so wouldn't be a problem running in a large loop, for example when calculating the website estimations. Frustratingly, `flexsurv` and `flexsurvcure` survival models are extremely slower and so would be unable to be used for this purpose, however, they would be fine for a single run, such as is needed for a publication.

```{r, echo=F}
data.frame(methods=c('legacy_default', 'legacy_cure', 'new_default', 'new_flex', 'new_cure'),
           times=c(legacy_speed[3], legacy_cure_speed[3], new_speed[3], new_flex_speed[3], new_cure_speed[3])
) %>% arrange(times)
```

## Parallelising code

The option to parallelise the bootstrapping was provided with the original rprev implementation, but hasn't yet been implemented in the latest version. This is something that I'd like to introduce, although it's worth bearing in mind that the runtimes of the implementation using cure models will still be extremely slow. I'm not sure if it's a priority to get this working straight away, however, so I should probably focus on getting the current implementation uploaded to CRAN.  

```{r, echo=F}
system.time(prevalence(index='2015-09-01', 
                             num_years_to_estimate=c(5, 10, 20, 50), 
                             data=aml, 
                             inc_formula = DateOfDiag ~ sex,
                             surv_model=flexsurvreg(Surv(stime, status) ~ sex + age, data=aml, dist='weibull'),
                             population_size = 1e6,
                             death_column = 'EventDate',
                       N_boot = 100))
```

```{r, echo=F}
prevalence(index='2015-09-01', 
                             num_years_to_estimate=c(5, 10, 20, 50), 
                             data=aml, 
                             inc_formula = DateOfDiag ~ sex,
                             surv_model=flexsurvreg(Surv(stime, status) ~ sex + age, data=aml, dist='weibull'),
                             population_size = 1e6,
                             death_column = 'EventDate',
                       N_boot = 100,
           n_cores = 2)
```


# Further Work

Areas of further exploration and work include:

Is the mixture cure model plausible? Is this difference with the original model justifiable? 

Does the long runtime of the cure model implementation using `flexsurvcure` render it unsuitable for use? Or just use it with a smaller number of simulations? One option is to provide it with the package as others may find it useful, but not use it for our website estimations. It is relatively common in software development to release a tool in a form that is suitable for general use, but use a more restricted version for internal applications

Small bits:

  - Is it worth looking more into having covariate effects on the survival function itself or just on the cure modelling?
  - Get more distributions working with the default optimised `survreg` survival model
  - I need to make unit tests for the new functions
